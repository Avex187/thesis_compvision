{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87ea9b0",
   "metadata": {},
   "source": [
    "### This is the main code that performs model training (60 models) with 3 resampled distributions, 4 model architectures, and 5 datasets with various sources and number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86cc25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os, shutil\n",
    "import tempfile\n",
    "from os import listdir\n",
    "import clr_callback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import mixed_precision, regularizers\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.layers import Input, Add, Dropout, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity, he_normal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, CSVLogger\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.applications import InceptionV3, Xception, MobileNetV3Large,EfficientNetB0,EfficientNetV2B0\n",
    "from resnet import resnet18\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix, matthews_corrcoef\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89524748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.set_cmap('gray')\n",
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5a698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in tf.config.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b80a1",
   "metadata": {},
   "source": [
    "### Initial setting of several hyperparameters, as well as the use of *mixed precision* from NVIDIA CUDA/CU-DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.05)\n",
    "\n",
    "clr = clr_callback.CyclicLR(base_lr=1e-4, max_lr=5e-3,\n",
    "               step_size=2000, mode='triangular2')\n",
    "    \n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.005, patience = 6,  restore_best_weights=True)\n",
    "lrs = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25675a26",
   "metadata": {},
   "source": [
    "### Specify the dataset folder in training process (Model HQ/HP-S/HP-L/RS-S/RS-L) = (Model A-B-C-D-E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train_path'\n",
    "val_path = 'val_path'\n",
    "test_path = 'test_path'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11a8309",
   "metadata": {},
   "source": [
    "### Pipeline Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cac9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datagen(train_path, val_path, test_path, target_size = (256,256), batch_size = 16, efficient = False):\n",
    "    if efficient:\n",
    "        train_datagen = image.ImageDataGenerator(\n",
    "            rescale = 1.,\n",
    "        )\n",
    "    else:\n",
    "        train_datagen = image.ImageDataGenerator(\n",
    "            rescale = 1./255,\n",
    "        )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=target_size,\n",
    "        batch_size= batch_size,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='categorical',\n",
    "        shuffle = True\n",
    "    )\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=target_size,\n",
    "        batch_size= batch_size,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='categorical',\n",
    "        shuffle = False\n",
    "    )\n",
    "    \n",
    "    test_generator = train_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=target_size,\n",
    "        batch_size= batch_size,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='categorical',\n",
    "        shuffle = False\n",
    "    )\n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf144681",
   "metadata": {},
   "source": [
    "### Utility Functions for Confusion Matrix Plotting and Simple Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (9,12)\n",
    "\n",
    "def plot_model_history(model, path):\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    ax1.plot(model.history['accuracy'])\n",
    "    ax1.plot(model.history['val_accuracy'])\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Val'], loc='upper left')\n",
    "    \n",
    "    ax2.plot(model.history['loss'], 'b')\n",
    "    ax2.plot(model.history['val_loss'], 'r')\n",
    "    ax2.set_title('Training and Validation loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train Loss', 'Val Loss'], loc='upper left')\n",
    "    fig.savefig(path, bbox_inches = 'tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(df_confusion, path, title='Confusion Matrix'):\n",
    "    print(df_confusion)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(title)\n",
    "\n",
    "    heatmaps = sns.heatmap(df_confusion, annot=True, cmap = \"viridis\",\n",
    "               vmin = 0, vmax = 1)\n",
    "    plt.setp(heatmaps.get_xticklabels(), rotation=30)\n",
    "    plt.setp(heatmaps.get_yticklabels(), rotation=30)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_classifier(model,generator, testing_size, batch_size, evaluate = False, efficient_net = False, \n",
    "                      path_report = None):\n",
    "    Y_pred = model.predict(generator)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    k = matthews_corrcoef(generator.classes, y_pred)\n",
    "    print(f'Matthew Correlation Coefficient : {k:.2f}')\n",
    "    \n",
    "    df_confusion_ori = pd.crosstab(generator.classes, y_pred, \n",
    "                               rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    df_confusion = pd.crosstab(generator.classes, y_pred, \n",
    "                               rownames=['Actual'], colnames=['Predicted'], margins=True, normalize = \"index\")\n",
    "    df_confusion.rename(columns={0: 'Confined Masonry', 1 : 'RC Infilled', 2 : 'Timber', 3 : 'Unconfined'}, \n",
    "              index={0: 'Confined Masonry', 1 : 'RC Infilled', 2 : 'Timber', 3 : 'Unconfined'}, inplace = True)\n",
    "    plot_confusion_matrix(df_confusion[:4][:], path = path_report)\n",
    "    \n",
    "    print('Classification Report')\n",
    "    target_names = ['Confined', 'RC', 'Timber', 'Unconfined']\n",
    "    print(classification_report(generator.classes, y_pred, target_names=target_names))\n",
    "    \n",
    "    if evaluate:\n",
    "        tipologi = {0 : 'Confined', 1 : 'RC Infilled', 2 : 'Timber', 3 : 'Unconfined'}\n",
    "        generator.reset()\n",
    "        print_index = 0\n",
    "        showimg = 1\n",
    "        plt.figure(figsize=(16,8))\n",
    "        while(print_index < len(y_pred)):\n",
    "            x_batch, y_batch = next(generator)\n",
    "            for k, (img, lbl) in enumerate(zip(x_batch, y_batch)):\n",
    "                if(showimg == 4):\n",
    "                    plt.figure(figsize=(16,8))\n",
    "                    showimg = 1\n",
    "                if (y_pred[print_index] != np.argmax(lbl)):\n",
    "                    if efficient_net:\n",
    "                        plt.subplot(1, 4, showimg)#4 rows with 8 images.\n",
    "                        showimg += 1\n",
    "                        plt.title('Prediksi :' + str(tipologi[y_pred[print_index]]) + ', Aktual :' + str(tipologi[np.argmax(lbl)]), \n",
    "                                  fontsize = 9)\n",
    "                        plt.axis('off')\n",
    "                        plt.tight_layout()\n",
    "                        plt.imshow(img/255.)\n",
    "                    else:\n",
    "                        plt.subplot(1, 4, showimg)#4 rows with 8 images.\n",
    "                        showimg += 1\n",
    "                        plt.title('Prediksi :' + str(y_pred[print_index]) + ', Aktual :' + str(np.argmax(lbl)), \n",
    "                                  fontsize = 9)\n",
    "                        plt.axis('off')\n",
    "                        plt.tight_layout()\n",
    "                        plt.imshow(img)\n",
    "                print_index += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dcc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = create_datagen(train_path, val_path, test_path,\n",
    "                                                                       batch_size = 16,efficient = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f441252",
   "metadata": {},
   "source": [
    "### Specification of additional *class weight* coefficient to balance the unbalanced situation of the dataset (extra effort after augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "               class_weight = 'balanced',\n",
    "                classes = np.unique(validation_generator.classes), \n",
    "                y = validation_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7fe8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17f832",
   "metadata": {},
   "source": [
    "### Utility Functions for initiating deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "def add_regularization(model, regularizer = regularizers.l2(0.001)):\n",
    "    if not isinstance(regularizer, regularizers.Regularizer):\n",
    "        print(\"Regularizer must be a subclass of tf.keras.regularizers.Regularizer\")\n",
    "        return model\n",
    "\n",
    "    for layer in model.layers:\n",
    "        for attr in ['kernel_regularizer']:\n",
    "            if hasattr(layer, attr):\n",
    "                setattr(layer, attr, regularizer)\n",
    "\n",
    "    model_json = model.to_json()\n",
    "\n",
    "    tmp_weights_path = os.path.join(tempfile.gettempdir(), 'tmp_weights.h5')\n",
    "    model.save_weights(tmp_weights_path)\n",
    "\n",
    "    model = models.model_from_json(model_json)\n",
    "    \n",
    "    model.load_weights(tmp_weights_path, by_name=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape = (256,256,3)))\n",
    "    model.add(Conv2D(8, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(Conv2D(8, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(Conv2D(8, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Conv2D(16, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(Conv2D(16, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(Conv2D(16, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Conv2D(32, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(Conv2D(32, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(Conv2D(32, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Conv2D(64, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(Conv2D(64, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(Conv2D(64, 3, activation = 'relu', padding = 'valid'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, kernel_regularizer=regularizers.l1(0.01),\n",
    "                    activity_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, kernel_regularizer=regularizers.l1(0.01),\n",
    "                    activity_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation = 'softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate=1e-4, \n",
    "                                                                      beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False), \n",
    "                  metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2809d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_models()\n",
    "add_regularization(model)\n",
    "model.summary(show_trainable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a961ac7",
   "metadata": {},
   "source": [
    "### Data generator experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80775383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(16, 32))\n",
    "for k, (img, lbl) in enumerate(zip(x_batch, y_batch)):\n",
    "    plt.subplot(8, 4, k+1)#4 rows with 8 images.\n",
    "    plt.title(str(lbl))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace18af",
   "metadata": {},
   "source": [
    "## Model Experimentation Function with various parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f60829",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This experimental function is actively used in my study. Parameter:\n",
    "\n",
    "model = The type of model whose performance is being reviewed through the training and validation process\n",
    "train_gen = Object generator to generate photos for the training process\n",
    "validation_gen = Generator object to generate photos for validation process (never seen by model)\n",
    "epoch_sch = Setting the number of epochs for each cycle of the fine-tuning process\n",
    "fine_tune_sch = Freeze/unfreeze layer settings for each cycle of the fine-tuning process\n",
    "lr_sch = Learning rate schedule, the change in the learning rate value in each cycle of the fine-tuning process. \n",
    "        When the fine-tuning approaches the earlier layer of CNN, the learning rate used is gradually smaller\n",
    "validation_sample = Number of samples in the validation set\n",
    "model_name = The name of the model to be saved to local disk\n",
    "label_smooth = Smoothing label parameter to provide soft label\n",
    "es = Early stopping object to stop training when overfitting starts\n",
    "lrs = object learning rate schedule, reducing the learning rate value at epoch > 10 negatively exponentially for\n",
    "      guarantee stable convergence\n",
    "spe = Steps per epoch, for certain cases where the dataset is very large, speeding up the training process with consequences\n",
    "      performance\n",
    "save_epoch = Cycle fine-tuning where the model starts to be saved gradually to evaluate its performance in the learning stage\n",
    "             certain\n",
    "'''\n",
    "\n",
    "def experiment(model, train_gen, validation_gen, \n",
    "               epoch_sch, fine_tune_sch, lr_sch, \n",
    "               validation_sample, class_weight, model_name,\n",
    "               label_smooth = 0.2, es = es, lrs = lrs, spe = None, save_epoch = 0):\n",
    "    for i in range(len(epoch_sch)):\n",
    "        fine_tune = fine_tune_sch[i]\n",
    "        epochs = epoch_sch[i]\n",
    "        learning_rates = lr_sch[i]\n",
    "    \n",
    "        for layer in model.layers[:fine_tune]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[fine_tune:]:\n",
    "            layer.trainable = True\n",
    "        model.compile(loss = CategoricalCrossentropy(from_logits=False, label_smoothing=label_smooth, axis=-1), \n",
    "                                optimizer = Adam(learning_rate=learning_rates, beta_1=0.9, beta_2=0.999, \n",
    "                                            epsilon=None, amsgrad=False), \n",
    "                               metrics = ['accuracy'])\n",
    "        print(f'Training Model for {epochs} epoch, fine-tuned at {fine_tune}, and with learning rate of {learning_rates}')\n",
    "        model_title = model_name + str(i+1)\n",
    "        csv_logger = CSVLogger('Misc/temp Graph/'+model_title+' Report.csv', append=True)\n",
    "        hist = model.fit(\n",
    "            train_gen,\n",
    "            epochs = epochs,\n",
    "            validation_data=validation_gen,\n",
    "            class_weight = class_weight,\n",
    "            callbacks=[es, lrs, csv_logger],\n",
    "            steps_per_epoch = spe,\n",
    "            verbose = 2\n",
    "        )\n",
    "        plot_model_history(hist, path = 'Misc/temp Graph/'+str(model_title)+' trainlog.jpg')\n",
    "        if(i >= (len(epoch_sch)-5)):\n",
    "            report_classifier(model,validation_generator,validation_sample,32,\n",
    "                              path_report = 'Misc/temp Graph/'+model_title+' Report.jpg')\n",
    "        tf.keras.backend.clear_session()\n",
    "        if(i >= save_epoch):\n",
    "            model.save(r'Deep Learning Models/Typology Classifier/' + model_title + '.h5')\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a8877",
   "metadata": {},
   "source": [
    "### Training + Testing with pretrained InceptionV3 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93df3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Inception():\n",
    "    base = InceptionV3(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_shape = (256, 256, 3),\n",
    "        pooling = \"max\",\n",
    "        classes = 4,\n",
    "        classifier_activation=\"softmax\",\n",
    "    )\n",
    "    out = Dropout(0.4)(base.output)\n",
    "    out = Dense(32, activation='relu', kernel_initializer=initializer)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(0.4)(out)\n",
    "    out = Dense(4, activation='softmax', kernel_initializer=\"glorot_uniform\")(out)\n",
    "\n",
    "    model = Model(inputs = base.input,outputs=out)\n",
    "    add_regularization(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7357e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = create_datagen(train_path, val_path, test_path, \n",
    "                                                                       batch_size = 16, efficient = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_Inception()\n",
    "\n",
    "for i,layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9428e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_schedule = [10, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25]\n",
    "fine_tune_schedule = [311, 299, 268, 228, 196, 164, 132, 100, 86, 63, 40,  4]\n",
    "lr_schedule = [1e-3, 1.33e-4, 1.33e-4, 1.33e-4, 1.33e-4, 1e-4, 7e-5, 6e-5, 4e-5, 2e-5, 2e-5, 1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f7d07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(model, train_generator, validation_generator,\n",
    "           epoch_schedule, fine_tune_schedule, lr_schedule, \n",
    "           validation_sample = 381, class_weight = d_class_weights, \n",
    "           model_name = 'Model RSL - InceptionV3 - D3 - ',\n",
    "           label_smooth = 0.2, es = es, lrs = lrs, save_epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4802ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "report_classifier(model,test_generator,388,16,\n",
    "                 path_report = 'Misc/temp Graph/'+'TEST Model RSL - InceptionV3 - D3 - '+' Report.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96489534",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception = tf.keras.models.load_model('Deep Learning Models\\Typology Classifier\\Model E - InceptionV3 - 2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f62335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2368bf",
   "metadata": {},
   "source": [
    "### Training + Testing with pretrained Xception Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Xception(\n",
    "    include_top = False,\n",
    "    weights = \"imagenet\",\n",
    "    input_shape = (256, 256, 3),\n",
    "    pooling = \"max\"\n",
    ")\n",
    "out = Dropout(0.5)(base.output)\n",
    "out = Dense(32, activation='relu', kernel_initializer=initializer)(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Dropout(0.5)(out)\n",
    "out = Dense(4, activation='softmax', kernel_initializer=\"glorot_uniform\")(out)\n",
    "\n",
    "model = Model(inputs = base.input,outputs=out)\n",
    "add_regularization(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566358f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = create_datagen(train_path, val_path, test_path, \n",
    "                                                                       batch_size = 16, efficient = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_schedule = [10, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25]\n",
    "fine_tune_schedule = [133, 126, 115, 105, 95, 85, 75, 65, 55, 45, 35, 25, 15, 1]\n",
    "lr_schedule = [2e-3, 2.66e-4,2.66e-4, 2.66e-4, 2.66e-4, 2.66e-4, 1e-4,1e-4, 9e-5, 8e-5, 5e-5, 3e-5, 2e-5, 1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab89cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf7967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(model, train_generator, validation_generator,\n",
    "           epoch_schedule, fine_tune_schedule, lr_schedule, \n",
    "           validation_sample = 381, class_weight = d_class_weights, \n",
    "           model_name = 'Model RSL - Xception - D3 - ',\n",
    "           label_smooth = 0.2, es = es, lrs = lrs, save_epoch = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e2c244",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "report_classifier(model,test_generator,388,16,\n",
    "                 path_report = 'Misc/temp Graph/'+'TEST Model RSL - Xception - D3 - '+' Report.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e973cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8c12b3",
   "metadata": {},
   "source": [
    "### Training + Testing with pretrained MobileNet V3L Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d077caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mobileNet():\n",
    "    base = MobileNetV3Large(\n",
    "        input_shape= (256, 256, 3),\n",
    "        alpha=1.0,\n",
    "        include_top = False,\n",
    "        weights= \"imagenet\",\n",
    "        classes = 4,\n",
    "        pooling = \"max\",\n",
    "        dropout_rate = 0.5,\n",
    "    )\n",
    "    out = Dropout(0.5)(base.output)\n",
    "    out = Dense(32, activation='relu', kernel_initializer=initializer)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(4, activation='softmax', kernel_initializer=\"glorot_uniform\")(out)\n",
    "\n",
    "    model = Model(inputs = base.input,outputs=out)\n",
    "    add_regularization(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_mobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = create_datagen(train_path, val_path, test_path,\n",
    "                                                                       batch_size = 32, efficient = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_schedule = [10, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25]\n",
    "fine_tune_schedule = [262, 256, 233, 210, 187, 164, 142, 127, 112, 97, 82, 65, 48, 31,22, 1]\n",
    "lr_schedule = [1e-3, 1e-4, 1e-4, 1e-4, 1e-4, 1e-4, 1e-4, 8e-5, 8e-5, 7e-5, 6e-5, 4e-5, 2e-5, 2e-5, 2e-5, 1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a7a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea4219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(model, train_generator, validation_generator,\n",
    "           epoch_schedule, fine_tune_schedule, lr_schedule, \n",
    "           validation_sample = 381, class_weight = d_class_weights, \n",
    "           model_name = 'Model RSL - Mobile - D1 - ',\n",
    "           label_smooth = 0.2, es = es, lrs = lrs, save_epoch = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_classifier(model,test_generator,388,32,\n",
    "                 path_report = 'Misc/temp Graph/'+'TEST Model RSL - Mobile - D1 - '+' Report.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efc691",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403b88af",
   "metadata": {},
   "source": [
    "### Training + Testing with pretrained EfficientNet B0 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb55cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_EfficientB0():\n",
    "    base = EfficientNetB0(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_shape = (256, 256, 3),\n",
    "        pooling = \"max\",\n",
    "        classes = 4\n",
    "    )\n",
    "    out = Dropout(0.5)(base.output)\n",
    "    out = Dense(32, activation='relu', kernel_initializer=initializer)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(4, activation='softmax', kernel_initializer=\"glorot_uniform\")(out)\n",
    "\n",
    "    model = Model(inputs = base.input,outputs=out)\n",
    "    add_regularization(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d77902",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_EfficientB0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7456631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = create_datagen(train_path, val_path, test_path, \n",
    "                                                                       batch_size = 16, efficient = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "    \n",
    "model.summary(show_trainable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d49bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_schedule = [10, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18]\n",
    "fine_tune_schedule = [238, 234, 162,147, 132, 119, 104, 89, 75, 60, 46, 31, 17,3]\n",
    "lr_schedule = [1e-2, 1e-3, 1e-3, 1e-3, 1e-3, 6e-4, 6e-4, 3e-4, 3e-4, 3e-4, 8e-5, 8e-5, 8e-5, 4e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b8471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(model, train_generator, validation_generator,\n",
    "           epoch_schedule, fine_tune_schedule, lr_schedule, \n",
    "           validation_sample = 101, class_weight = d_class_weights, \n",
    "           model_name = 'Model RSS - Efficient - D3 - ',\n",
    "           label_smooth = 0.2, es = es, lrs = lrs, save_epoch = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568b001",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "report_classifier(model,test_generator,106,16, \n",
    "                 path_report = 'Misc/temp Graph/'+'TEST Model RSS - Efficient - D3 - '+' Report.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
