{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6846253",
   "metadata": {},
   "source": [
    "## This code performs hyperparameter optimization for each of the CNN model trained on various datasets\n",
    "\n",
    "### The hyperparameters optimized with random search were:\n",
    "\n",
    "- Adam learning rate $\\alpha$\n",
    "- Batch size\n",
    "\n",
    "Random searches performed starts with coarse tuning to $\\alpha$, followed by successive fine tuning until the best $\\alpha$ resulting in lowest validation error were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adaad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os, shutil\n",
    "import tempfile\n",
    "from os import listdir\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import mixed_precision, regularizers\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.layers import Input, Add, Dropout, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity, he_normal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, CSVLogger\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.applications import InceptionV3, Xception, MobileNetV3Large,EfficientNetB0,EfficientNetV2B0\n",
    "from resnet import resnet18\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix, matthews_corrcoef\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6a7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.set_cmap('gray')\n",
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in tf.config.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0626dc",
   "metadata": {},
   "source": [
    "### Initial settings for hyperparameter and usage of *mixed precision* from NVIDIA CUDA/CU-DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "    \n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.005, patience = 6,  restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1a8f5",
   "metadata": {},
   "source": [
    "### Data Generator Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba895e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datagen(train_path, val_path, test_path, target_size = (256,256), batch_size = 16, efficient = False):\n",
    "    if efficient:\n",
    "        train_datagen = image.ImageDataGenerator(\n",
    "            rescale = 1.,\n",
    "        )\n",
    "    else:\n",
    "        train_datagen = image.ImageDataGenerator(\n",
    "            rescale = 1./255,\n",
    "        )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=target_size,\n",
    "        batch_size= batch_size,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='categorical',\n",
    "        shuffle = True\n",
    "    )\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=target_size,\n",
    "        batch_size= batch_size,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='categorical',\n",
    "        shuffle = False\n",
    "    )\n",
    "    \n",
    "    test_generator = train_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=target_size,\n",
    "        batch_size= batch_size,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='categorical',\n",
    "        shuffle = False\n",
    "    )\n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b26bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "def add_regularization(model, regularizer = regularizers.l2(0.01)):\n",
    "    if not isinstance(regularizer, regularizers.Regularizer):\n",
    "        print(\"Regularizer must be a subclass of tf.keras.regularizers.Regularizer\")\n",
    "        return model\n",
    "\n",
    "    for layer in model.layers:\n",
    "        for attr in ['kernel_regularizer']:\n",
    "            if hasattr(layer, attr):\n",
    "                setattr(layer, attr, regularizer)\n",
    "\n",
    "    model_json = model.to_json()\n",
    "\n",
    "    tmp_weights_path = os.path.join(tempfile.gettempdir(), 'tmp_weights.h5')\n",
    "    model.save_weights(tmp_weights_path)\n",
    "\n",
    "    model = models.model_from_json(model_json)\n",
    "    \n",
    "    model.load_weights(tmp_weights_path, by_name=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a4fb4",
   "metadata": {},
   "source": [
    "### Utility for Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ffb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Inception():\n",
    "    base = InceptionV3(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_shape = (256, 256, 3),\n",
    "        pooling = \"max\",\n",
    "        classes = 4,\n",
    "        classifier_activation=\"softmax\",\n",
    "    )\n",
    "    out = Dropout(0.4)(base.output)\n",
    "    out = Dense(32, activation='relu', kernel_initializer=initializer)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(0.4)(out)\n",
    "    out = Dense(4, activation='softmax', kernel_initializer=\"glorot_uniform\")(out)\n",
    "\n",
    "    model = Model(inputs = base.input,outputs=out)\n",
    "    add_regularization(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab221f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Xception():  \n",
    "    base = Xception(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_shape = (256, 256, 3),\n",
    "        pooling = \"max\"\n",
    "    )\n",
    "    out = Dropout(0.5)(base.output)\n",
    "    out = Dense(32, activation='relu', kernel_initializer=initializer)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(4, activation='softmax', kernel_initializer=\"glorot_uniform\")(out)\n",
    "\n",
    "    model = Model(inputs = base.input,outputs=out)\n",
    "    add_regularization(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b433ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mobileNet():\n",
    "    base = MobileNetV3Large(\n",
    "        input_shape= (256, 256, 3),\n",
    "        alpha=1.0,\n",
    "        include_top = False,\n",
    "        weights= \"imagenet\",\n",
    "        classes = 4,\n",
    "        pooling = \"max\",\n",
    "        dropout_rate = 0.3,\n",
    "    )\n",
    "    out = Dropout(0.5)(base.output)\n",
    "    out = Dense(32, activation='relu', kernel_initializer=initializer)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(4, activation='softmax', kernel_initializer=\"glorot_uniform\")(out)\n",
    "\n",
    "    model = Model(inputs = base.input,outputs=out)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15bfc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_EfficientB0():\n",
    "    base = EfficientNetB0(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_shape = (256, 256, 3),\n",
    "        pooling = \"max\",\n",
    "        classes = 4\n",
    "    )\n",
    "    out = Dropout(0.5)(base.output)\n",
    "    out = Dense(64, activation='relu', kernel_initializer=initializer)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(4, activation='softmax', kernel_initializer=\"glorot_uniform\")(out)\n",
    "\n",
    "    model = Model(inputs = base.input,outputs=out)\n",
    "    add_regularization(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f1125",
   "metadata": {},
   "source": [
    "### Define dataset paths and generator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bceeea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train_paths'\n",
    "val_path = 'val_paths'\n",
    "test_path = 'test_paths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator, test_generator = create_datagen(train_path, val_path, test_path,\n",
    "                                                                       batch_size = batch,efficient = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(16, 32))\n",
    "for k, (img, lbl) in enumerate(zip(x_batch, y_batch)):\n",
    "    plt.subplot(8, 4, k+1)#4 rows with 8 images.\n",
    "    plt.title(str(lbl))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501bc35b",
   "metadata": {},
   "source": [
    "### Optimization for Model HQ,HPS,RSS - Inc, Xcp, Mbl, Eff - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371162d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_hyperparam = (100, 0, 0)\n",
    "epochs = 8\n",
    "\n",
    "lr_trial = [1e-2, 1e-3, 1e-4, 5e-5]\n",
    "batch_trial = [8, 16, 32]\n",
    "\n",
    "trial = 10\n",
    "\n",
    "#Round 1 Random Search (Coarse)\n",
    "for _ in range(trial):\n",
    "    lr = lr_trial[randint(0,3)]\n",
    "    batch = batch_trial[randint(0,2)]\n",
    "    print(lr, batch)\n",
    "    train_generator, validation_generator, test_generator = create_datagen(train_path, val_path, test_path,\n",
    "                                                                       batch_size = batch,efficient = True)\n",
    "    model = make_EfficientB0()\n",
    "    model.compile(loss = CategoricalCrossentropy(from_logits=False, label_smoothing = 0.2, axis=-1), \n",
    "                                optimizer = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, \n",
    "                                            epsilon=None, amsgrad=False), \n",
    "                               metrics = ['accuracy'])\n",
    "    hist = model.fit(\n",
    "            train_generator,\n",
    "            epochs = epochs,\n",
    "            validation_data=validation_generator,\n",
    "            verbose = 2\n",
    "        )\n",
    "    val_loss = np.nanmin(hist.history['val_loss'])\n",
    "    print(f\"Minimum val loss is {val_loss}\")\n",
    "    if val_loss < best_hyperparam[0]:\n",
    "        best_hyperparam = (val_loss, lr, batch)\n",
    "        print(best_hyperparam)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181fdab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"START RANDOM SEARCH ROUND 2 (FINE)\")\n",
    "\n",
    "epochs = 5\n",
    "train_generator, validation_generator, test_generator = create_datagen(train_path, val_path, test_path,\n",
    "                                                                       batch_size = best_hyperparam[2],efficient = False)\n",
    "\n",
    "#Round 2 Random Search (Fine)\n",
    "lr_trial_2 = [ best_hyperparam[1] / 2, best_hyperparam[1] * 2 ]\n",
    "for lr in lr_trial_2:\n",
    "    model = make_EfficientB0()\n",
    "    model.compile(loss = CategoricalCrossentropy(from_logits=False, label_smoothing = 0.2, axis=-1), \n",
    "                                optimizer = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, \n",
    "                                            epsilon=None, amsgrad=False), \n",
    "                               metrics = ['accuracy'])\n",
    "    hist = model.fit(\n",
    "            train_generator,\n",
    "            epochs = epochs,\n",
    "            validation_data=validation_generator,\n",
    "            verbose = 2\n",
    "        )\n",
    "    val_loss = np.nanmin(hist.history['val_loss'])\n",
    "    print(f\"Minimum val loss is {val_loss}\")\n",
    "    if val_loss < best_hyperparam[0]:\n",
    "        best_hyperparam = (val_loss, lr, batch)\n",
    "        print(best_hyperparam)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "print(f\"START RANDOM SEARCH ROUND 3 (VERY FINE)\")\n",
    "#Round 3 Random Search (Very Fine)\n",
    "lr_trial_3 = [ best_hyperparam[1] / 3, best_hyperparam[1] * 2/3 ,  \n",
    "              best_hyperparam[1] * 4/3, best_hyperparam[1] * 5/3]\n",
    "for lr in lr_trial_3:\n",
    "    model = make_mobileNet()\n",
    "    model.compile(loss = CategoricalCrossentropy(from_logits=False, label_smoothing = 0.2, axis=-1), \n",
    "                                optimizer = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, \n",
    "                                            epsilon=None, amsgrad=False), \n",
    "                               metrics = ['accuracy'])\n",
    "    hist = model.fit(\n",
    "            train_generator,\n",
    "            epochs = epochs,\n",
    "            validation_data=validation_generator,\n",
    "            verbose = 2\n",
    "        )\n",
    "    val_loss = np.nanmin(hist.history['val_loss'])\n",
    "    print(f\"Minimum val loss is {val_loss}\")\n",
    "    if val_loss < best_hyperparam[0]:\n",
    "        best_hyperparam = (val_loss, lr, batch)\n",
    "        print(best_hyperparam)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
