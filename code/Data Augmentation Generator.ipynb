{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "365df291",
   "metadata": {},
   "source": [
    "## This code does the full augmentation process for each dataset, before feeding the data to the CNN models for experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f794a",
   "metadata": {},
   "source": [
    "### Importing necessary library for augmentation utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "#OpenCV-Python\n",
    "import cv2\n",
    "import cv\n",
    "\n",
    "# imgaug\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img \n",
    "\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML, Image\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38058e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defining data path\n",
    "\n",
    "def loadimage_path(source_dir,filename):\n",
    "    file_path = source_dir + '/' + filename\n",
    "    image = cv2.imread(file_path)\n",
    "    return image\n",
    "\n",
    "def loadimage_array(img_arr):\n",
    "    plt.imshow(img_arr, interpolation='nearest')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def move_file_fromfolder(source, destination):\n",
    "    allfiles = os.listdir(source)\n",
    "    for f in allfiles:\n",
    "        shutil.move(source + f, destination + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018eaf50",
   "metadata": {},
   "source": [
    "## Augmentation Transformation Pipeline Processing (Randomized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ed49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a pipeline.\n",
    "# The example has been taken from the documentation\n",
    "aug_pipeline = iaa.Sequential([\n",
    "        iaa.SomeOf((3,6),[\n",
    "            iaa.OneOf([\n",
    "                iaa.SaltAndPepper((0.01, 0.02), per_channel=True),\n",
    "                iaa.CoarseDropout(p=(0.01, 0.02), size_percent = 0.85, per_channel=0.5),\n",
    "            ]),\n",
    "            iaa.Rotate((-9, 9), mode = \"symmetric\"),\n",
    "            iaa.Fliplr(0.5),\n",
    "            iaa.Cutout(nb_iterations=(2, 4), size=0.07, squared=True, fill_mode=\"gaussian\", fill_per_channel=True),\n",
    "            iaa.Affine(scale = (0.9, 1.2), backend = 'cv2'),\n",
    "            iaa.GammaContrast((0.85, 1.5)),\n",
    "            iaa.AddToHueAndSaturation((-40, 40), per_channel=True),\n",
    "            iaa.pillike.EnhanceColor(factor = (0.6, 1.3)),\n",
    "            iaa.GaussianBlur(sigma = (0,0.5))\n",
    "        ]), \n",
    "    ],\n",
    "    random_order=True # apply the augmentations in random order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4461d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_from_width = iaa.Sequential([\n",
    "        iaa.Resize({\"height\": \"keep-aspect-ratio\", \"width\": 256}),\n",
    "        iaa.CenterCropToFixedSize(height=256, width=256),\n",
    "    ],\n",
    "    random_order=False # apply the augmentations in random order\n",
    ")\n",
    "\n",
    "resize_from_height = iaa.Sequential([\n",
    "        iaa.Resize({\"height\": 256, \"width\": \"keep-aspect-ratio\"}),\n",
    "        iaa.CenterCropToFixedSize(height=256, width=256),\n",
    "    ],\n",
    "    random_order=False # apply the augmentations in random order\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93952d79",
   "metadata": {},
   "source": [
    "# Augmentation Function (preprocessing, augment, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_photo(source_file, target_dir, num_augment):\n",
    "    img = cv2.imread(source_file)\n",
    "    images_aug = np.array([aug_pipeline.augment_image(img) for _ in range(num_augment)])\n",
    "    for i in range(0, num_augment):\n",
    "        im = cv2.cvtColor(images_aug[i], cv2.COLOR_BGR2RGB)\n",
    "        im = Image.fromarray(im)\n",
    "        target_filename = target_dir + 'A' + str(i+1) + '.jpg'\n",
    "        im.save(target_filename)\n",
    "    print('Augmentation process for file done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b8a62",
   "metadata": {},
   "source": [
    "### Trial Mode for dummy folder (evaluate augmentation quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0cca13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augment_photo(r\"source_path\",\n",
    "             r\"destination_path\",number_of_augment_for_each_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf3c636",
   "metadata": {},
   "source": [
    "### Function to augment 1 folder at a time, and saving to specified folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_folder(source_dir, target_dir, num_augment, hard_limit):\n",
    "    limit = 0\n",
    "    for i, file in enumerate(os.listdir(source_dir)):\n",
    "        img = loadimage_path(source_dir, file)\n",
    "        images_aug = np.array([aug_pipeline.augment_image(img) for _ in range(num_augment)])\n",
    "        for i in range(0, num_augment):\n",
    "            limit += 1\n",
    "            im = cv2.cvtColor(images_aug[i], cv2.COLOR_BGR2RGB)\n",
    "            im = Image.fromarray(im)\n",
    "            target_filename = target_dir + 'A' + str(i+1) + '- ' + file\n",
    "            if(limit > hard_limit):\n",
    "                break\n",
    "            im.save(target_filename)\n",
    "    print('Augmentation process for folder ' + source_dir + ' done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1e63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_folder(source_dir, target_dir):\n",
    "    for i, file in enumerate(os.listdir(source_dir)):\n",
    "        path = source_dir + '/' + file\n",
    "        img = cv2.imread(path)\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        if((h != 256) | (w != 256)):\n",
    "            if(h > w):\n",
    "                images_resized = np.array(resize_from_width.augment_image(img))\n",
    "            else:\n",
    "                images_resized = np.array(resize_from_height.augment_image(img))\n",
    "            #im = Image.fromarray(images_aug)\n",
    "            target_filename = target_dir + '/' + file\n",
    "            cv2.imwrite(target_filename, images_resized)\n",
    "    print('Resizing process for folder ' + source_dir.split('/')[5] + ' done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587fc8c8",
   "metadata": {},
   "source": [
    "### Execution of Augmentation process for each folder \n",
    "\n",
    "#### (Model A : HQ, Model B : HP-S, Model C : HP-L , Model D : RS-S , Model E : RS-L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [\"Distribution 1\", \"Distribution 2\", \"Distribution 3\"]\n",
    "models = [\"Model A\", \"Model B\", \"Model C\", \"Model D\", \"Model E\"]\n",
    "typologies = [\"Confined\", \"RC Infilled\", \"Timber\", \"Unconfined\"]\n",
    "small_sampling = [[\"Confined\",2, 580], [\"RC Infilled\",8,764], [\"Timber\",15, 814], [\"Unconfined\",33, 844]]\n",
    "hp_sampling = [[\"Confined\",2, 1064], [\"RC Infilled\",8,1404], [\"Timber\",13, 1475], [\"Unconfined\",20, 1519]]\n",
    "rs_sampling = [[\"Confined\",2, 2160], [\"RC Infilled\",8,2845], [\"Timber\",14, 3012], [\"Unconfined\",38, 3155]]\n",
    "\n",
    "for dist in dists:\n",
    "    for model in models:\n",
    "        if((model == \"Model A\") or (model == \"Model B\") or (model == \"Model D\")):\n",
    "            for sampling in small_sampling:\n",
    "                source_dir = \"Categorized Datasets/Dataset/\" + dist + \"/\" + model + \"/train/\" + sampling[0] + \"/\"\n",
    "                print(source_dir)\n",
    "                augment_folder(source_dir, source_dir, sampling[1], sampling[2])\n",
    "        elif(model == \"Model C\"):\n",
    "            for sampling in hp_sampling:\n",
    "                source_dir = \"Categorized Datasets/Dataset/\" + dist + \"/\" + model + \"/train/\" + sampling[0] + \"/\"\n",
    "                print(source_dir)\n",
    "                augment_folder(source_dir, source_dir, sampling[1], sampling[2])\n",
    "        else:\n",
    "            for sampling in rs_sampling:\n",
    "                source_dir = \"Categorized Datasets/Dataset/\" + dist + \"/\" + model + \"/train/\" + sampling[0] + \"/\"\n",
    "                print(source_dir)\n",
    "                augment_folder(source_dir, source_dir, sampling[1], sampling[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
