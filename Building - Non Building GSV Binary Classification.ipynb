{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92bd3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os, shutil\n",
    "import tempfile\n",
    "from os import listdir\n",
    "import clr_callback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import mixed_precision, regularizers\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.layers import Input, Add, Dropout, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity, he_normal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, CSVLogger\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.applications import InceptionV3, Xception, MobileNetV3Large,EfficientNetB0,EfficientNetV2B0\n",
    "from resnet import resnet18\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix, matthews_corrcoef\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import os, shutil\n",
    "from os import listdir\n",
    "from skimage.io import imshow, imread, imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = BinaryCrossentropy(\n",
    "    from_logits=False, label_smoothing=0.0, axis=-1,\n",
    "    name='binary_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd606709",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.05)\n",
    "\n",
    "clr = clr_callback.CyclicLR(base_lr=1e-4, max_lr=5e-3,\n",
    "               step_size=2000, mode='triangular2')\n",
    "    \n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.005, patience = 7,  restore_best_weights=True)\n",
    "lrs = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c03ad8f",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3029607",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (9,12)\n",
    "\n",
    "def plot_model_history(model, path):\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    ax1.plot(model.history['accuracy'])\n",
    "    ax1.plot(model.history['val_accuracy'])\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Val'], loc='upper left')\n",
    "    \n",
    "    ax2.plot(model.history['loss'], 'b')\n",
    "    ax2.plot(model.history['val_loss'], 'r')\n",
    "    ax2.set_title('Training and Validation loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train Loss', 'Val Loss'], loc='upper left')\n",
    "    fig.savefig(path, bbox_inches = 'tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89757266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(df_confusion, path, title='Confusion Matrix'):\n",
    "    print(df_confusion)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(title)\n",
    "\n",
    "    heatmaps = sns.heatmap(df_confusion, annot=True, cmap = \"viridis\",\n",
    "               vmin = 0, vmax = 1)\n",
    "    plt.setp(heatmaps.get_xticklabels(), rotation=30)\n",
    "    plt.setp(heatmaps.get_yticklabels(), rotation=30)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e39b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_classifier(model,generator, testing_size, batch_size, evaluate = False, efficient_net = False, \n",
    "                      path_report = None):\n",
    "    Y_pred = model.predict(generator)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    k = matthews_corrcoef(generator.classes, y_pred)\n",
    "    print(f'Matthew Correlation Coefficient : {k:.2f}')\n",
    "    \n",
    "    df_confusion_ori = pd.crosstab(generator.classes, y_pred, \n",
    "                               rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    df_confusion = pd.crosstab(generator.classes, y_pred, \n",
    "                               rownames=['Actual'], colnames=['Predicted'], margins=True, normalize = \"index\")\n",
    "    df_confusion.rename(columns={0: 'Confined Masonry', 1 : 'RC Infilled', 2 : 'Timber', 3 : 'Unconfined'}, \n",
    "              index={0: 'Confined Masonry', 1 : 'RC Infilled', 2 : 'Timber', 3 : 'Unconfined'}, inplace = True)\n",
    "    plot_confusion_matrix(df_confusion[:4][:], path = path_report)\n",
    "    \n",
    "    print('Classification Report')\n",
    "    target_names = ['Confined', 'RC', 'Timber', 'Unconfined']\n",
    "    print(classification_report(generator.classes, y_pred, target_names=target_names))\n",
    "    \n",
    "    if evaluate:\n",
    "        tipologi = {0 : 'Confined', 1 : 'RC Infilled', 2 : 'Timber', 3 : 'Unconfined'}\n",
    "        generator.reset()\n",
    "        print_index = 0\n",
    "        showimg = 1\n",
    "        plt.figure(figsize=(16, 32))\n",
    "        while(print_index < len(y_pred)):\n",
    "            x_batch, y_batch = next(generator)\n",
    "            if(showimg == 1 or showimg == 32):\n",
    "                plt.figure(figsize=(16, 32))\n",
    "            for k, (img, lbl) in enumerate(zip(x_batch, y_batch)):\n",
    "                if(showimg == 32):\n",
    "                    showimg = 1\n",
    "                if (y_pred[print_index] != np.argmax(lbl)):\n",
    "                    if efficient_net:\n",
    "                        plt.subplot(8, 4, showimg)#4 rows with 8 images.\n",
    "                        showimg += 1\n",
    "                        plt.title('Prediksi :' + str(tipologi[y_pred[print_index]]) + ', Aktual :' + str(tipologi[np.argmax(lbl)]), \n",
    "                                  fontsize = 9)\n",
    "                        plt.imshow(img/255.)\n",
    "                    else:\n",
    "                        plt.subplot(8, 4, showimg)#4 rows with 8 images.\n",
    "                        showimg += 1\n",
    "                        plt.title('Prediksi :' + str(y_pred[print_index]) + ', Aktual :' + str(np.argmax(lbl)), \n",
    "                                  fontsize = 9)\n",
    "                        plt.imshow(img)\n",
    "                print_index += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d48c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datagen(data_path, target_size = (256,256), batch_size = 8, split = 0.3):\n",
    "    train_datagen = image.ImageDataGenerator(\n",
    "        rescale = 1.,\n",
    "        horizontal_flip = True,\n",
    "        rotation_range = 5,\n",
    "        fill_mode = 'reflect',\n",
    "        width_shift_range= 0.05,\n",
    "        zoom_range = [0.8, 1.1],\n",
    "        brightness_range = [0.8, 1.2],\n",
    "        channel_shift_range= 10.0,\n",
    "        #preprocessing_function= crop,\n",
    "        validation_split = split\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=target_size,\n",
    "        batch_size= batch_size,\n",
    "        class_mode='binary',\n",
    "        subset='training')\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=target_size,\n",
    "        batch_size= batch_size,\n",
    "        class_mode='binary',\n",
    "        subset='validation') # set as validation data\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f07afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'building_nonbuilding/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d832fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator = create_datagen(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8390508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "               class_weight = 'balanced',\n",
    "                classes = np.unique(validation_generator.classes), \n",
    "                y = validation_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17321434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(model, train_gen, validation_gen, \n",
    "               epoch_sch, fine_tune_sch, lr_sch, \n",
    "               validation_sample, class_weight, model_name,\n",
    "               label_smooth = 0.15, es = es, lrs = lrs, spe = None, save_epoch = 0):\n",
    "    for i in range(len(epoch_sch)):\n",
    "        fine_tune = fine_tune_sch[i]\n",
    "        epochs = epoch_sch[i]\n",
    "        learning_rates = lr_sch[i]\n",
    "    \n",
    "        for layer in model.layers[:fine_tune]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[fine_tune:]:\n",
    "            layer.trainable = True\n",
    "        model.compile(loss = BinaryCrossentropy(from_logits=False, label_smoothing=label_smooth, axis=-1, name='binary_crossentropy'), \n",
    "                                optimizer = Adam(learning_rate=learning_rates, beta_1=0.9, beta_2=0.999, \n",
    "                                            epsilon=None, amsgrad=False), \n",
    "                               metrics = ['accuracy'])\n",
    "        print(f'Training Model for {epochs} epoch, fine-tuned at {fine_tune}, and with learning rate of {learning_rates}')\n",
    "        model_title = model_name + str(i+1)\n",
    "        csv_logger = CSVLogger('Misc/temp Graph/'+model_title+' Report.csv', append=True)\n",
    "        hist = model.fit(\n",
    "            train_gen,\n",
    "            epochs = epochs,\n",
    "            validation_data=validation_gen,\n",
    "            class_weight = class_weight,\n",
    "            callbacks=[es, lrs, csv_logger],\n",
    "            steps_per_epoch = spe,\n",
    "            verbose = 2\n",
    "        )\n",
    "        plot_model_history(hist, path = 'Misc/temp Graph/'+str(model_title)+' trainlog.jpg')\n",
    "        if(i >= (len(epoch_sch)-5)):\n",
    "            tf.keras.backend.clear_session()\n",
    "        if(i >= save_epoch):\n",
    "            model.save(r'Deep Learning Models/Typology Classifier/' + model_title + '.h5')\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = he_normal()\n",
    "\n",
    "def add_regularization(model, regularizer = regularizers.l2(0.01)):\n",
    "    if not isinstance(regularizer, regularizers.Regularizer):\n",
    "        print(\"Regularizer must be a subclass of tf.keras.regularizers.Regularizer\")\n",
    "        return model\n",
    "\n",
    "    for layer in model.layers:\n",
    "        for attr in ['kernel_regularizer']:\n",
    "            if hasattr(layer, attr):\n",
    "                setattr(layer, attr, regularizer)\n",
    "\n",
    "    model_json = model.to_json()\n",
    "\n",
    "    tmp_weights_path = os.path.join(tempfile.gettempdir(), 'tmp_weights.h5')\n",
    "    model.save_weights(tmp_weights_path)\n",
    "\n",
    "    model = models.model_from_json(model_json)\n",
    "    \n",
    "    model.load_weights(tmp_weights_path, by_name=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimage_path(source_dir,filename):\n",
    "    file_path = source_dir + '/' + filename\n",
    "    image = imread(file_path)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b315c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70002a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(16, 32))\n",
    "for k, (img, lbl) in enumerate(zip(x_batch, y_batch)):\n",
    "    plt.subplot(8, 4, k+1)#4 rows with 8 images.\n",
    "    plt.title(str(lbl))\n",
    "    plt.imshow(img/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973876eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aecfa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588e835",
   "metadata": {},
   "source": [
    "## EfficientNet B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_EfficientB0():\n",
    "    base = EfficientNetB0(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_shape = (256, 256, 3),\n",
    "        pooling = \"max\",\n",
    "        classes = 2\n",
    "    )\n",
    "    out = Dropout(0.5)(base.output)\n",
    "    out = Dense(16, activation='relu', kernel_initializer=initializer)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(1, activation='sigmoid', kernel_initializer=\"glorot_uniform\")(out)\n",
    "\n",
    "    model = Model(inputs = base.input,outputs=out)\n",
    "    add_regularization(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea64a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_EfficientB0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44aa448",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_schedule = [10, 25, 25, 15]\n",
    "fine_tune_schedule = [238, 234, 162, 3]\n",
    "lr_schedule = [12e-4, 9e-4, 7e-4, 5e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(show_trainable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d8e3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(model, train_generator, validation_generator,\n",
    "           epoch_schedule, fine_tune_schedule, lr_schedule, \n",
    "           validation_sample = 1178, class_weight = d_class_weights, \n",
    "           model_name = 'Model B-NB ',\n",
    "           label_smooth = 0.2, es = es, lrs = lrs, save_epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e02d525",
   "metadata": {},
   "source": [
    "## Prediksi Foto Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf13568",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eff = models.load_model('Deep Learning Models/Model B-NB.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a481f679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_path = 'Generator Results 3/'\n",
    "save_path = 'Generator Results 3/'\n",
    "for i, fname in enumerate(listdir(test_path)):\n",
    "        fpath = os.path.join(test_path, fname)\n",
    "        img = image.load_img(fpath, target_size=(256, 256))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        img_preprocessed = img_batch\n",
    "        \n",
    "        prediction = model_eff.predict(img_preprocessed)\n",
    "        prediction = np.squeeze(prediction)\n",
    "    \n",
    "        file_name = save_path + \"{:.4f}\".format(prediction) + '_' + str(fname)\n",
    "        img_array = img_array/255.\n",
    "        matplotlib.image.imsave(file_name, img_array)\n",
    "        \n",
    "        if(i % 500 == 0):\n",
    "            print(\"Prediksi ke-\" + str(i))\n",
    "        #im.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f98298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
